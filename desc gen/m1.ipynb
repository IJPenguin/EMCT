{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ViT\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow_text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)  # Adjust vocabulary size as needed\n",
    "vit_model = ViT(model_name=\"google/vit-base-patch32\", include_top=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image_input(image):\n",
    "    image = tf.keras.applications.imagenet_utils.preprocess_input(image)  # Preprocess for ViT\n",
    "    image_features = vit_model(image)[0]  # Extract features\n",
    "    return image_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(images, captions):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, captions))\n",
    "    dataset = dataset.map(lambda x, y: (prepare_image_input(x), tokenizer(y)))\n",
    "    # Apply other transformations as needed (e.g., shuffling, batching)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = vit_model.input\n",
    "encoder_outputs = vit_model.output\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
    "decoder_embedding = Embedding(input_dim=tokenizer.num_words, output_dim=embedding_dim)(decoder_inputs)\n",
    "decoder_lstm = LSTM(units=512, return_sequences=True)(decoder_embedding, initial_state=encoder_outputs)\n",
    "decoder_outputs = Dense(tokenizer.num_words, activation=\"softmax\")(decoder_lstm)\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.001)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "# Load your image and caption data\n",
    "images, captions = ...  # Load your dataset\n",
    "dataset = create_dataset(images, captions)\n",
    "\n",
    "model.fit(dataset, epochs=10)  # Adjust epochs as needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(image):\n",
    "    image_features = prepare_image_input(image)\n",
    "    decoder_input = tf.expand_dims([tokenizer.word_index[\"<start>\"]], 0)\n",
    "    for i in range(max_caption_length):\n",
    "        predictions = model.predict([image_features, decoder_input])\n",
    "        predicted_id = tf.argmax(predictions[0, -1, :])\n",
    "        predicted_word = tokenizer.index_word[predicted_id.numpy()]\n",
    "        if predicted_word == \"<end>\":\n",
    "            break\n",
    "        decoder_input = tf.expand_dims([predicted_id], 0)\n",
    "    caption = tokenizer.sequences_to_texts(decoder_input.numpy())[0]\n",
    "    return caption\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
